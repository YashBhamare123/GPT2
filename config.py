# Model Architecture
vocab_size = 50257
embed_dim = 768
seq_length = 1024
n_layers = 12
batch_size = 4
n_heads = 12

# Training Loop
device = 'mps'
